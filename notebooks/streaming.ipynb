{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "compound-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install findspark\n",
    "import findspark\n",
    "findspark.init() \n",
    "\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import explode, split, col, from_json, window\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType, TimestampType\n",
    "import kafka\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10_2.12:3.1.1,org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1 pyspark-shell'\n",
    "\n",
    "os.environ['PYSPARK_PYTHON']='/Users/aptroost/.pyenv/versions/3.6.13/bin/python'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON']='/Users/aptroost/.pyenv/versions/3.6.13/bin/python'\n",
    "\n",
    "os.environ['SPARK_HOME']='/usr/local/Cellar/apache-spark/3.1.1/libexec'\n",
    "os.environ['PYTHONPATH']='/usr/local/Cellar/apache-spark/3.1.1/libexec/python'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "metropolitan-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start session with Spark\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1')\\\n",
    "    .appName(\"routeData\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "heavy-rubber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from kafka\n",
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"routes_data\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "crude-portrait",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the dataframa schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "finite-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the datatype for value to a string\n",
    "string_df = df.selectExpr(\"CAST(value AS STRING)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "secret-idaho",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the new dataframa schema\n",
    "string_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "optional-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a schema for the df\n",
    "schema = StructType([\n",
    "    StructField(\"id\", StringType()),\n",
    "    StructField(\"datetime\", TimestampType()),\n",
    "    StructField(\"airline\", StringType()),\n",
    "    StructField(\"airline_id\", IntegerType()),\n",
    "    StructField(\"source_airport\", StringType()),\n",
    "    StructField(\"source_airport_id\", IntegerType()),\n",
    "    StructField(\"destination_airport\", StringType()),\n",
    "    StructField(\"destination_airport_id\", IntegerType()),\n",
    "    StructField(\"codeshare\", BooleanType()),\n",
    "    StructField(\"stops\", IntegerType()),\n",
    "    StructField(\"equipment\", StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "noted-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the data present in the column value and apply the schema on it\n",
    "json_df = string_df \\\n",
    "    .withColumn(\"jsonData\", \n",
    "                from_json(col(\"value\"), \n",
    "                          schema)) \\\n",
    "    .select(\"jsondata.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "foster-personality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- datetime: timestamp (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- airline_id: integer (nullable = true)\n",
      " |-- source_airport: string (nullable = true)\n",
      " |-- source_airport_id: integer (nullable = true)\n",
      " |-- destination_airport: string (nullable = true)\n",
      " |-- destination_airport_id: integer (nullable = true)\n",
      " |-- codeshare: boolean (nullable = true)\n",
      " |-- stops: integer (nullable = true)\n",
      " |-- equipment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Print out the dataframa schema\n",
    "json_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "subject-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(q, name, outputMode, outputFormat):\n",
    "    from IPython.display import display, clear_output\n",
    "    import pyspark.sql.functions as F\n",
    "    import pyspark.sql.types as T\n",
    "    import uuid\n",
    "    from pyspark.sql.functions import desc\n",
    "\n",
    "    unique_query_name = str(uuid.uuid4()).replace('-','')\n",
    "    query = q \\\n",
    "        .writeStream \\\n",
    "        .outputMode(outputMode) \\\n",
    "        .format(outputFormat) \\\n",
    "        .queryName(unique_query_name) \\\n",
    "        .start()\n",
    "\n",
    "    while True:\n",
    "        sleep(1)\n",
    "        clear_output(wait=True)\n",
    "        display(query.status)\n",
    "\n",
    "        spark_query = spark.sql('SELECT * FROM ' + unique_query_name)    \n",
    "        df_pandas = spark_query.toPandas()\n",
    "        df_pandas.to_csv(name + '.csv', index=False)\n",
    "        \n",
    "        if len(df_pandas.index) > 0: \n",
    "            return df_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "elder-advantage",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = json_df.select(\"*\")\n",
    "\n",
    "display(run_query(q, \"dump_table\", \"update\", \"memory\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "modified-calculation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Waiting for data to arrive',\n",
       " 'isDataAvailable': False,\n",
       " 'isTriggerActive': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_airport</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORD</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PEK</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LHR</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CDG</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FRA</td>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LAX</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DFW</td>\n",
       "      <td>938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>JFK</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AMS</td>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_airport  count\n",
       "0            ATL   1830\n",
       "1            ORD   1116\n",
       "2            PEK   1070\n",
       "3            LHR   1050\n",
       "4            CDG   1048\n",
       "5            FRA    994\n",
       "6            LAX    984\n",
       "7            DFW    938\n",
       "8            JFK    912\n",
       "9            AMS    906"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q = json_df.select(\"*\")\\\n",
    "        .groupBy(\n",
    "            json_df.source_airport\n",
    "        )\\\n",
    "        .count()\\\n",
    "        .orderBy(\n",
    "            col('count').desc()\n",
    "        )\\\n",
    "        .limit(10)\n",
    "\n",
    "display(run_query(q, \"top10_source_airport\", \"complete\", \"memory\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "loose-productivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Waiting for data to arrive',\n",
       " 'isDataAvailable': False,\n",
       " 'isTriggerActive': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    (2021-05-02 13:39:30, 2021-05-02 13:40:00)\n",
       "1    (2021-05-02 13:39:30, 2021-05-02 13:40:00)\n",
       "2    (2021-05-02 13:40:00, 2021-05-02 13:40:30)\n",
       "3    (2021-05-02 13:52:00, 2021-05-02 13:52:30)\n",
       "4    (2021-05-02 13:52:30, 2021-05-02 13:53:00)\n",
       "5    (2021-05-02 13:39:00, 2021-05-02 13:39:30)\n",
       "6    (2021-05-02 13:52:30, 2021-05-02 13:53:00)\n",
       "7    (2021-05-02 13:53:00, 2021-05-02 13:53:30)\n",
       "8    (2021-05-02 13:51:30, 2021-05-02 13:52:00)\n",
       "9    (2021-05-02 13:53:30, 2021-05-02 13:54:00)\n",
       "Name: window, dtype: object"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = json_df.select(\"*\")\\\n",
    "        .groupBy(\n",
    "            window(\n",
    "                json_df.datetime, \n",
    "                \"30 seconds\", \n",
    "                \"30 seconds\"),\n",
    "            json_df.equipment\n",
    "        )\\\n",
    "        .count()\\\n",
    "        .orderBy(\n",
    "            col('count').desc(), \n",
    "            col('equipment').desc()\n",
    "        )\\\n",
    "        .limit(10)\n",
    "\n",
    "df_pandas = run_query(q, \"top10_equipment_30min_window\", \"complete\", \"memory\")\n",
    "for idx, row in df_pandas.iterrows():\n",
    "    df_pandas.at[idx, 'start'] = row['window'][0]\n",
    "    df_pandas.at[idx, 'end'] = row['window'][1]\n",
    "df_pandas.pop(\"window\")\n",
    "df_pandas['start'] = df_pandas['start'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_pandas['end'] = df_pandas['end'].dt.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "third-consequence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"equipment\":\"738\",\"count\":4338,\"start\":\"2021-05-02 13:39:30\",\"end\":\"2021-05-02 13:40:00\"},{\"equipment\":\"320\",\"count\":3763,\"start\":\"2021-05-02 13:39:30\",\"end\":\"2021-05-02 13:40:00\"},{\"equipment\":\"320\",\"count\":3054,\"start\":\"2021-05-02 13:40:00\",\"end\":\"2021-05-02 13:40:30\"},{\"equipment\":\"738\",\"count\":2748,\"start\":\"2021-05-02 13:52:00\",\"end\":\"2021-05-02 13:52:30\"},{\"equipment\":\"320\",\"count\":2694,\"start\":\"2021-05-02 13:52:30\",\"end\":\"2021-05-02 13:53:00\"},{\"equipment\":\"320\",\"count\":2298,\"start\":\"2021-05-02 13:39:00\",\"end\":\"2021-05-02 13:39:30\"},{\"equipment\":\"738\",\"count\":2105,\"start\":\"2021-05-02 13:52:30\",\"end\":\"2021-05-02 13:53:00\"},{\"equipment\":\"320\",\"count\":1799,\"start\":\"2021-05-02 13:53:00\",\"end\":\"2021-05-02 13:53:30\"},{\"equipment\":\"320\",\"count\":1555,\"start\":\"2021-05-02 13:51:30\",\"end\":\"2021-05-02 13:52:00\"},{\"equipment\":\"320\",\"count\":1546,\"start\":\"2021-05-02 13:53:30\",\"end\":\"2021-05-02 13:54:00\"}]'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-failure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-tours",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-field",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-richmond",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-chocolate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-sense",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-pontiac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3613",
   "language": "python",
   "name": "3613"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
