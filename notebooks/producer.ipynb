{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "second-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyenv global 3.6.13\n",
    "# python3 -m pip install ipykernel avro_validator uuid kafka pypandoc pyspark pandas pyarrow\n",
    "\n",
    "import avro_validator\n",
    "import json\n",
    "import uuid\n",
    "import datetime\n",
    "from kafka import KafkaProducer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "danish-membership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "routes.dat \t\t2377148 bytes\n",
      "data_schema.json \t1670 bytes\n"
     ]
    }
   ],
   "source": [
    "# Local file that will be send to Kafka row by row\n",
    "filename_data   = 'routes.dat'\n",
    "filename_schema = 'data_schema.json'\n",
    "\n",
    "print(str(filename_data) + ' \\t\\t' + str(os.path.getsize(filename_data)) + ' bytes')\n",
    "print(str(filename_schema) + ' \\t' + str(os.path.getsize(filename_schema)) + ' bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "known-survivor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'record',\n",
       " 'doc': 'This event records routes between airports on airlines.',\n",
       " 'name': 'AirlineRouteEvent',\n",
       " 'fields': [{'name': 'id',\n",
       "   'type': 'string',\n",
       "   'doc': 'A universally unique identifier that is generated using random numbers'},\n",
       "  {'name': 'datetime',\n",
       "   'type': 'string',\n",
       "   'doc': 'The produced event datetime in UTC format'},\n",
       "  {'name': 'airline',\n",
       "   'type': 'string',\n",
       "   'doc': '2-letter (IATA) or 3-letter (ICAO) code of the airline'},\n",
       "  {'name': 'airline_id',\n",
       "   'type': 'int',\n",
       "   'doc': 'Unique OpenFlights identifier for airline'},\n",
       "  {'name': 'source_airport',\n",
       "   'type': 'string',\n",
       "   'doc': '3-letter (IATA) or 4-letter (ICAO) code of the source airport'},\n",
       "  {'name': 'source_airport_id',\n",
       "   'type': 'int',\n",
       "   'doc': 'Unique OpenFlights identifier for source airport'},\n",
       "  {'name': 'destination_airport',\n",
       "   'type': 'string',\n",
       "   'doc': '3-letter (IATA) or 4-letter (ICAO) code of the destination airport'},\n",
       "  {'name': 'destination_airport_id',\n",
       "   'type': 'int',\n",
       "   'doc': 'Unique OpenFlights identifier for destination airport'},\n",
       "  {'name': 'codeshare',\n",
       "   'type': 'boolean',\n",
       "   'doc': 'True if this flight is a codeshare (that is, not operated by Airline, but another carrier)'},\n",
       "  {'name': 'stops',\n",
       "   'type': 'int',\n",
       "   'doc': \"Number of stops on this flight ('0' for direct)\"},\n",
       "  {'name': 'equipment',\n",
       "   'type': 'string',\n",
       "   'doc': '3-letter codes for plane type(s) generally used on this flight, separated by spaces'}]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open data schema in external file\n",
    "# avro schema style source: https://avro.apache.org/docs/current/spec.html\n",
    "with open(filename_schema) as json_file:\n",
    "    data_schema = json.load(json_file)\n",
    "data_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "prescription-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Kafka producer\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=['localhost:9092'], \n",
    "    value_serializer=lambda x: json.dumps(x).encode('utf-8')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "upper-steps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read local file\n",
    "open_data = open(filename_data, 'r')\n",
    "lines = open_data.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "duplicate-cattle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total errors by var transform\t68\t6.800000000000001%\n",
      "Total errors by invalid schema\t0\t0.0%\n",
      "Total success \t\t\t932\t93.2%\n",
      "Total count\t\t\t1000\t100.0%\n"
     ]
    }
   ],
   "source": [
    "# Validate data and send row by row to Kafka\n",
    "\n",
    "def strToBool(codeshare):\n",
    "    if codeshare == 'Y':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "count_error_transform_var    = 0\n",
    "count_error_invalid_schema   = 0\n",
    "count_success = 0\n",
    "count_total = 0\n",
    "\n",
    "# clear file\n",
    "f = open(\"error.txt\", \"w\")\n",
    "f.close()\n",
    "\n",
    "for line in lines[0:1000]:\n",
    "# for line in lines:\n",
    "    count_total += 1\n",
    "    line = line.replace('\\n','')\n",
    "    listOfStr = line.strip().split(',')\n",
    "    \n",
    "    try:\n",
    "    # Pragmatic approach\n",
    "        line_dict = {\n",
    "            'id':                      str(uuid.uuid4()),\n",
    "            'datetime':                str(datetime.datetime.utcnow()),\n",
    "            'airline':                 str(listOfStr[0]),\n",
    "            'airline_id':              int(listOfStr[1]),\n",
    "            'source_airport':          str(listOfStr[2]),\n",
    "            'source_airport_id':       int(listOfStr[3]),\n",
    "            'destination_airport':     str(listOfStr[4]),\n",
    "            'destination_airport_id':  int(listOfStr[5]),\n",
    "            'codeshare':               strToBool(listOfStr[6]),\n",
    "            'stops':                   int(listOfStr[7]),\n",
    "            'equipment':               str(listOfStr[8]),\n",
    "        }\n",
    "        parsed_schema = avro_validator.schema.Schema(json.dumps(data_schema)).parse()\n",
    "        if parsed_schema.validate(line_dict):\n",
    "            producer.send(\"routes_data\", value=line_dict)\n",
    "            count_success += 1\n",
    "        else:\n",
    "            f = open(\"error.txt\", \"a\")\n",
    "            f.write('Schema invalid: ' + line + '\\n')\n",
    "            f.close()\n",
    "            count_error_invalid_schema += 1\n",
    "    except:\n",
    "        f = open(\"error.txt\", \"a\")\n",
    "        f.write('A variable type transformation failed: ' + line + '\\n')\n",
    "        f.close()\n",
    "        count_error_transform_var += 1\n",
    "        pass\n",
    "    \n",
    "print('Total errors by var transform\\t' + str(count_error_transform_var) + '\\t' + str(count_error_transform_var/count_total*100) + '%')\n",
    "print('Total errors by invalid schema\\t' + str(count_error_invalid_schema) + '\\t' + str(count_error_invalid_schema/count_total*100) + '%')\n",
    "print('Total success \\t\\t\\t' + str(count_success) + '\\t' + str(count_success/count_total*100) + '%')\n",
    "print('Total count\\t\\t\\t' + str(count_total) + '\\t' + str(count_total/count_total*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-roots",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "missing-liberal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Total count': 1000},\n",
       " {'Total count (%)': 100.0},\n",
       " {'Total success': 932},\n",
       " {'Total success (%)': 93.2},\n",
       " {'Total errors by var transform': 68},\n",
       " {'Total errors by var transform (%)': 6.8},\n",
       " {'Total errors by invalid schema': 0},\n",
       " {'Total errors by invalid schema (%)': 0.0}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result = [\n",
    "#     {'Total count': count_total},\n",
    "#     {'Total count (%)': round(count_total/count_total*100,2)},\n",
    "#     {'Total success': count_success},\n",
    "#     {'Total success (%)': round(count_success/count_total*100,2)},\n",
    "#     {'Total errors by var transform': count_error_transform_var},\n",
    "#     {'Total errors by var transform (%)': round(count_error_transform_var/count_total*100, 2)},\n",
    "#     {'Total errors by invalid schema': count_error_invalid_schema},\n",
    "#     {'Total errors by invalid schema (%)': round(count_error_invalid_schema/count_total*100,2)}\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-volunteer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-samba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-cancer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-nevada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-sarah",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-norwegian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3613",
   "language": "python",
   "name": "3613"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
